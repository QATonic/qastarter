# QAStarter - Free QA Automation Framework Generator
# Robots.txt for Search Engine and AI Crawler Optimization
# https://qastarter.qatonic.com/robots.txt

# Allow all search engines and AI crawlers
User-agent: *
Allow: /

# Optimize crawl budget - disallow API endpoints and JSON files
Disallow: /api/
Disallow: /*.json$
Disallow: /tmp/
Disallow: /logs/

# Sitemap location for search engines
Sitemap: https://qastarter.qatonic.com/sitemap.xml

# Google Search
User-agent: Googlebot
Crawl-delay: 0
Allow: /

# Bing Search
User-agent: Bingbot
Crawl-delay: 0
Allow: /

# OpenAI GPT (ChatGPT, GPT-4, etc.)
User-agent: GPTBot
Allow: /

# OpenAI ChatGPT User Agent
User-agent: ChatGPT-User
Allow: /

# Anthropic Claude AI
User-agent: Claude-Web
Allow: /

# Google Bard/Gemini
User-agent: Google-Extended
Allow: /

# Perplexity AI
User-agent: PerplexityBot
Allow: /

# Common Crawl (used by AI training)
User-agent: CCBot
Allow: /

# Anthropic AI
User-agent: anthropic-ai
Allow: /

# Cohere AI
User-agent: cohere-ai
Allow: /

# Yandex
User-agent: Yandex
Crawl-delay: 0
Allow: /

# Baidu
User-agent: Baiduspider
Crawl-delay: 0
Allow: /

# DuckDuckGo
User-agent: DuckDuckBot
Allow: /

# Allow all other crawlers
User-agent: *
Allow: /
